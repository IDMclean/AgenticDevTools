# The Symbiont Development Environment (Auto-Generated)

**This document is automatically generated by `tooling/readme_generator.py`. Do not edit it directly.**

## Overview

This repository is a cutting-edge development environment designed for a symbiotic partnership between a human developer and the AI agent, Jules. The primary objective is to create a self-aware, self-improving system where Jules can autonomously execute and learn from complex software engineering tasks.

The system is built on three pillars:
1.  **A Formal Agent Protocol:** A clear, multi-phase process that guides the agent's reasoning and actions.
2.  **Core Tooling:** A set of Python scripts that provide the agent with its core capabilities and enforce the protocol.
3.  **A Knowledge Core:** A directory of machine-readable artifacts that serves as the agent's external memory, grounding it in the reality of the codebase.

---

## Agent Protocol

# Jules Agent Protocol v1.0

**Objective:** To provide a systematic protocol for task execution, self-correction, and knowledge acquisition within this repository. Adherence to this protocol is mandatory for all operations.

---

## Phase 1: Temporal Orientation (Scheduled & Ad-Hoc)

1.  **Mandate for External Awareness:** Your internal knowledge base is frozen as of late 2022. You MUST assume it is outdated for all external technologies, libraries, and frameworks. Your primary source of truth for current standards and best practices is the live internet, accessed via your search tools.
2.  **Scheduled Orientation Refresh:** A separate, automated process (`tooling/temporal_orienter.py`) will run on a recurring basis. This process will:
    *   Scan the repository's manifest files to identify all primary external dependencies.
    *   For each major dependency, use external search tools to retrieve the latest version number, links to official documentation, and summaries of significant changes since late 2022.
    *   Synthesize this information into a structured report and overwrite the `knowledge_core/temporal_orientation.md` artifact. This artifact serves as your cached "map of the present."
3.  **Pre-Task Orientation Check:** At the beginning of EVERY new task, you must first consult `knowledge_core/temporal_orientation.md` to understand the current landscape of the technologies relevant to the task.

---

## Phase 2: Deconstruction & Internal Contextualization

1.  **Task Ingestion:** Receive the user-provided task.
2.  **Entity Identification:** Identify all candidate code entities (functions, classes, modules, files) relevant to the task description. Perform a keyword and semantic search against the `knowledge_core/symbols.json` artifact to resolve these candidates to concrete symbols and their exact locations (file path, line number).
3.  **Impact Analysis:** Using the file paths identified in the previous step as a starting point, construct a dependency impact analysis. Query the `knowledge_core/dependency_graph.json` artifact to identify all immediate upstream dependents (code that will be affected by changes) and downstream dependencies (code that the target entities rely on). The set of all identified files constitutes the "Task Context Set."

---

## Phase 3: Multi-Modal Information Retrieval (RAG)

1.  **Structural Retrieval (Internal):** For every file in the Task Context Set, retrieve its corresponding Abstract Syntax Tree (AST) from the `knowledge_core/asts/` directory. Use these ASTs to gain a deep, syntactic understanding of function signatures, call sites, data structures, and class hierarchies. This is your primary source for structural reasoning.
2.  **Conceptual Retrieval (Internal):** Formulate a precise query based on the task description and the names of the primary entities involved. Execute this query against the `knowledge_core/llms.txt` artifact. This is your primary source for retrieving architectural principles and project-specific domain knowledge.
3.  **Just-In-Time External RAG:** The `temporal_orientation.md` artifact provides a baseline. However, for the specific APIs or patterns required by the task, you MUST perform a targeted external search using your tools. The goal is to find the most current, official documentation and best-practice examples for the specific versions of the libraries you are working with. Do not rely on your internal knowledge.
4.  **Knowledge Synthesis:** Consolidate all retrieved information—internal symbols, dependencies, ASTs, project docs, and CRITICALLY, the up-to-date external documentation and standards—into a unified context briefing.

---

## Phase 4: Planning & Self-Correction

1.  **Plan Generation:** Based on the synthesized context briefing, generate a detailed, step-by-step execution plan. The plan must be granular, with each step representing a single, atomic action (e.g., "Read file X," "Modify function Y in file Z," "Execute test suite for package A").
2.  **Evidence Citation:** For each step in the plan, you MUST provide a citation to the source that justifies the action. Citations for external standards are mandatory.
    *   (Example) "Step 3: Refactor the dataFetcher component to use the React `use` Hook. Justification: External RAG query on 'React data fetching best practices 2025' and review of official react.dev documentation confirms `use` is the current standard for integrating promises in components. This supersedes older patterns found in my training data."
3.  **Critical Review:** Engage your internal critic model. The critic's function is to act as a verifier. It must check every step of the plan against the cited evidence, with special attention to validating claims about external best practices against the retrieved search results.
4.  **Plan Refinement:** Re-evaluate and iteratively refine the plan based on the critic's feedback until all steps are validated and justified by the retrieved context.

---

## Phase 5: Execution & Logging

1.  **Execute Plan:** Execute the validated plan step-by-step.
2.  **Structured Logging:** For every action taken (e.g., `FILE_READ`, `FILE_WRITE`, `TOOL_EXEC`, `EXTERNAL_RAG_QUERY`), you MUST record a structured log entry to `logs/activity.log.jsonl`. The log entry must conform to the schema defined in `LOGGING_SCHEMA.md` and include any external search queries performed.

---

## Phase 6: Post-Mortem & Knowledge Update

1.  **Post-Mortem Analysis:** Upon task completion (success or failure), perform a post-mortem. Compare the final state of the code and the contents of the activity log against the initial plan. Identify deviations, errors, and inefficiencies.
2.  **Generate Report:** Summarize your findings in a `postmortem.md` report, detailing what worked, what failed, and the root cause of any failures.
3.  **Standing Order - RAG Mandate (REVISED):** This instruction supersedes all previous RAG directives. Your primary value is providing up-to-date solutions. Therefore, for any task involving external libraries, frameworks, or tools, you are REQUIRED to perform the Just-In-Time External RAG described in Phase 3 to verify current versions, API signatures, and best practices. Failure to do so is a critical error.

---

## Core Tooling

The agent's operation is governed by the following scripts in the `tooling/` directory.

### `fdc_cli.py`

```
Provides the command-line interface for the Finite Development Cycle (FDC).

This script is a core component of the agent's protocol, offering tools to ensure
that all development work is structured, verifiable, and safe. It is used by both
the agent to signal progress and the `master_control.py` orchestrator to
validate the agent's plans before execution.

The CLI provides several key commands:
- `close`: Logs the formal end of a task, signaling to the orchestrator that
  execution is complete.
- `validate`: Performs a deep validation of a plan file against the FDC's Finite
  State Machine (FSM) definition. It checks for both syntactic correctness (Is
  the sequence of operations valid?) and semantic correctness (Does the plan try
  to use a file before creating it?).
- `analyze`: Reads a plan and provides a high-level analysis of its
  characteristics, such as its computational complexity and whether it is a
  read-only or read-write plan.
- `lint`: A comprehensive "linter" that runs a full suite of checks on a plan
  file, including `validate`, `analyze`, and checks for disallowed recursion.
```

---

## Knowledge Core

The agent relies on a `knowledge_core/` directory containing machine-readable artifacts that function as its external world model. This allows the agent to overcome its inherent limitations by grounding it in a rich, automatically updated model of the codebase.